#### The config file for lifelong class incremental learning with All baseline methods.
#### For cora pubmed and citeseer we use the featBrd layer
#### For citeseer we need a smaller batch size due due to the GPU memory

dataset=citeseer
model=GAT #MLP APPNP SAGE GCN
device=cuda:0
seed=1

sample=10
jump=1
memory=500
batch=6
opt=SGD
merge=1

hidden =[64, 32]
drop = [0, 0]